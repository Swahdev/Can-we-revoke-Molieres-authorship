"ma",
"pois",
"qel",
#"ren",
"un",
"al",
"als",
#"fai",
#"faich",
#"mal",
#"pot",
"qe",
"sa",
"sia",
#"temps",
#"uert",
#"amor",
"canc",
#"cor",
#"cus",
#"deu",
"eil",
"fo",
#"puosc",
"qeil",
"qeis",
#"sen",
#"sos",
#"taing",
#"uol",
"anc",
"els",
#"fin",
#"fols",
#"fos",
"los",
#"noi",
"par",
"puois",
"qand",
"totz",
#"uas",
"us",
#"dir",
"ges",
"gran",
"grans",
"lieis",
"lor",
"mes",
"no",
"nois",
"pres",
#"saber",
#"sap",
#"seigner",
#"ten",
"trop",
"uers",
"an",
"autra",
"dan",
#"doutz",
#"dreich",
"dun",
"em",
"enon",
#"faitz",
#"farai",
#"fetz",
"fui",
#"gens",
"las",
"me",
#"merces",
"miei",
"nuills",
"pero",
"pos",
"sai",
#"sec",
#"seignor",
#"semblan",
#"seruir",
"sil",
"sim",
"tal",
#"trobar",
#"uai",
#"ual",
#"ualer",
#"uei",
#"uuoill",
"aitan",
"auer",
"autre",
#"bens",
#"bes",
"bon",
"cab",
"cal",
"cel",
"cels",
#"chantar",
#"cortes",
#"couen",
#"damor",
#"deman",
#"dieu",
#"dieus",
#"dirai",
#"drutz",
#"durarai",
"eu",
#"fassa",
#"fezes",
#"flors",
#"fora",
#"greu",
"il",
"lais",
#"mains",
#"met",
#"nais",
"nil",
#"noil",
"nol",
#"nomen",
#"nuill",
"pauc",
#"plagues",
#"pren",
#"pros",
"res",
#"talan",
"tro",
#"uetz",
#"ui",
#"uiurai",
#"uoler",
"uostre"),]
cansos
# Use sampling instead
for(i in 1:ncol(cansos)){
cansos[,i] = cansos[,i]/sum(cansos[,i])
}
FactoMineR::PCA(t(cansos))
CAH = cluster::agnes(t(cansos), metric = "manhattan", method = "ward")
plot(CAH, which.plots = 2)
#Z-transformation
for(i in 1:nrow(cansos)){
cansos[i,] = ( cansos[i,] - mean(cansos[i,]) )  / sd(cansos[i,])
}
#Feature length normalisation: length-normalized vectors (according to the Euclidean norm)', cf. Evert et al. 2017
for(i in 1:ncol(cansos)){
cansos[,i] = cansos[,i] / sqrt(sum(cansos[,i]^2))
}
CAH = cluster::agnes(t(cansos), metric = "manhattan", method = "ward")
plot(CAH, which.plots = 2)
cansos = read.csv("/home/jbc/Programmation/R/LexicoCansos/CorpusCanso_nouv_freq_200.csv", sep =";", header = TRUE, row.names = 1)
cansos = as.matrix(cansos)
cansos = cansos[!rownames(cansos) %in% c('§'),]
cansos = cansos[c("que",
"e",
"non",
"ni",
"per",
"tant",
"es",
"mas",
"de",
"si",
"car",
"cum",
"nom",
"mi",
"el",
"la",
"son",
"en",
"ieu",
"qieu",
"ab",
"ben",
"qem",
"ai",
"li",
"sui",
"qui",
"so",
"plus",
"qan",
"qen",
"ses",
#"cors",
"cui",
"don",
"et",
#"far",
"lo",
#"mos",
#"pretz",
"a",
"mon",
#"ioi",
"men",
"sieu",
"tot",
"com",
#"gen",
#"hom",
"ia",
"on",
"uos",
#"amors",
"anz",
"del",
"mais",
#"dompna",
"lai",
"ma",
"pois",
"qel",
#"ren",
"un",
"al",
"als",
#"fai",
#"faich",
#"mal",
#"pot",
"qe",
"sa",
"sia",
#"temps",
#"uert",
#"amor",
"canc",
#"cor",
#"cus",
#"deu",
"eil",
"fo",
#"puosc",
"qeil",
"qeis",
#"sen",
#"sos",
#"taing",
#"uol",
"anc",
"els",
#"fin",
#"fols",
#"fos",
"los",
#"noi",
"par",
"puois",
"qand",
"totz",
#"uas",
"us",
#"dir",
"ges",
"gran",
"grans",
"lieis",
"lor",
"mes",
"no",
"nois",
"pres",
#"saber",
#"sap",
#"seigner",
#"ten",
"trop",
"uers",
"an",
"autra",
"dan",
#"doutz",
#"dreich",
"dun",
"em",
"enon",
#"faitz",
#"farai",
#"fetz",
"fui",
#"gens",
"las",
"me",
#"merces",
"miei",
"nuills",
"pero",
"pos",
"sai",
#"sec",
#"seignor",
#"semblan",
#"seruir",
"sil",
"sim",
"tal",
#"trobar",
#"uai",
#"ual",
#"ualer",
#"uei",
#"uuoill",
"aitan",
"auer",
"autre",
#"bens",
#"bes",
"bon",
"cab",
"cal",
"cel",
"cels",
#"chantar",
#"cortes",
#"couen",
#"damor",
#"deman",
#"dieu",
#"dieus",
#"dirai",
#"drutz",
#"durarai",
"eu",
#"fassa",
#"fezes",
#"flors",
#"fora",
#"greu",
"il",
"lais",
#"mains",
#"met",
#"nais",
"nil",
#"noil",
"nol",
#"nomen",
#"nuill",
"pauc",
#"plagues",
#"pren",
#"pros",
"res",
#"talan",
"tro",
#"uetz",
#"ui",
#"uiurai",
#"uoler",
"uostre"),]
# Use sampling instead
for(i in 1:ncol(cansos)){
cansos[,i] = cansos[,i]/sum(cansos[,i])
}
minmax = MinMax(cansos)
CAH = cluster::agnes(minmax, method = "ward")
plot(CAH, which.plots = 2)
rownames(cansos)
sort(rownames(cansos))
?poweRlaw
?package
??poweRlaw
quit("no")
library("stemmatology")
data("fournival")
PCC(fournival)
setwd("~/Data/F/Articles et CR/Article_Corneille_Moliere/data_and_scripts_repository/DataS3_datasets-and-scripts")
1250/1500
22.8 * 0.8333333
# Loading corpus
# Lemma Pie without proper names
# TXM CQP Request: [frpos !=  'NOMpro' & frlemma != '[A-Z].*' ]
theatreLemma = as.matrix(
read.csv(file="explorat-lemma.csv", sep = ";", header = TRUE, row.names=1, quote = '\"'))
colnames(theatreLemma)
simpleClusterPurity = function(cah, k = 10){
# Get classes from the reference CAH
classes = cutree(cah, k = k)
# Classes as per alledged author
expected = sub("_.*", "", rownames(cah$data))
# purity
purity = NMF::purity(as.factor(classes), expected)
return(purity)
}
source("functions.R")
suspectedProperNames = scan("suspected_proper_names.txt", what = "character", sep =",")
functionWords = scan("function_words.txt", what = "character")
# Remove the tragi-comédie 'Le Prince Corsaire', as well as the second edition of Melite
toRemove = c("SCARRON_PRINCECORSAIRE",
"CORNEILLEP_MELITE")
theatreCompl = as.matrix(
read.csv(file="explorat-words.csv", sep = ";", header = TRUE, row.names=1, quote = '\"'))
# remove total freq
theatre = theatreCompl[, -1]
# remove generic errors
theatre = theatre[, !colnames(theatre) %in% toRemove]
colnames(theatre)[colSums(theatre) < 5000]
toRemove = c(toRemove, colnames(theatre)[colSums(theatre) < 5000])
# And consequently, Dorimond has only one play
theatre = theatre[, !colnames(theatre) %in% toRemove]
toRemove = c(toRemove, "DORIMOND_FEMMEINDUSTRIEUSE")
theatre = theatre[, !colnames(theatre) %in% toRemove]
colSums(theatre)
# Loading corpus
# Lemma Pie without proper names
# TXM CQP Request: [frpos !=  'NOMpro' & frlemma != '[A-Z].*' ]
theatreLemma = as.matrix(
read.csv(file="explorat-lemma.csv", sep = ";", header = TRUE, row.names=1, quote = '\"'))
theatre = theatreLemma[,-1]
theatre = theatre[, !colnames(theatre) %in% toRemove]
#Remove some suspected proper names that could have been mislabelled
theatre = theatre[!rownames(theatre) %in% suspectedProperNames,]
# and finally remove all rows of sum 0
theatre = theatre[rowSums(theatre) > 0,]
theatre2 = theatre
# Selection based on Moisl 2011
select = selection(theatre2, z = 1.645)
select = select[,4]
# Normalisations
theatre2 = relativeFreqs(theatre2)
# save data for robustness checks
theatreLemmaSave = theatre2
theatre2 = theatre2[select,]
theatre2 = normalisations(theatre2)
myCAH = cluster::agnes(t(theatre2), metric = "manhattan", method="ward")
# Save
CAHLemma = myCAH
#
cahPlotCol(myCAH, k = 12)
simpleClusterPurity(myCAH, k = 12)
cahPlotCol = function(x, main="Plot", xlab = paste(ncol(x$data), "features"), k = 3, lth = 7, lrect = -13, cex = 0.6, ylab = "height"){
# Redefining labels
x$order.lab = sub("CORNEILLEP","CP", x$order.lab)
x$order.lab = sub("CORNEILLET","CT", x$order.lab)
x$order.lab = sub("MOLIERE","M", x$order.lab)
x$order.lab = sub("OUVILLE","O", x$order.lab)
x$order.lab = sub("ROTROU","R", x$order.lab)
x$order.lab = sub("SCARRON","S", x$order.lab)
x$order.lab = sub("BOISSY","B", x$order.lab)
x$order.lab = sub("DANCOURT","DA", x$order.lab)
x$order.lab = sub("DUFRESNY","DU", x$order.lab)
x$order.lab = sub("NIVELLE","N", x$order.lab)
x$order.lab = sub("REGNARD","R", x$order.lab)
x$order.lab = sub("VOLTAIRE","V", x$order.lab)
x$order.lab = sub("BOURSAULT","B", x$order.lab)
x$order.lab = sub("CHEVALIER","C", x$order.lab)
x$order.lab = sub("DONNEAUDEVISE","DDV", x$order.lab)
x$order.lab = sub("DORIMOND","DOR", x$order.lab)
x$order.lab = sub("GILLET","G", x$order.lab)
x$order.lab = sub("LAFONTAINE","LF", x$order.lab)
x$order.lab = sub("QUINAULT","Q", x$order.lab)
# Avoid ambiguity between Molière's École des…
x$order.lab = sub("ECOLEDES","ECOLE", x$order.lab)
#Shorten labels
x$order.lab = substring(x$order.lab, 1, 10)
# Coloring them
labels = vector(length = length(x$order.lab))
labels[grep("M_", x$order.lab)] = "darkgreen"
labels[grep("CP_", x$order.lab)] = "red"
labels[grep("CT_", x$order.lab)] = "deeppink"  #"pink"
labels[grep("S_", x$order.lab)] = "darkgoldenrod2" #"yellow"
labels[grep("LF_", x$order.lab)] = "grey"
labels[grep("B_", x$order.lab)] = "purple"
labels[grep("Q_", x$order.lab)] = "cyan"
labels[grep("C_", x$order.lab)] = "darkgoldenrod4" #"orange"
labels[grep("DDV_", x$order.lab)] = "brown"
labels[grep("O_", x$order.lab)] = "indianred4" # "blue"
labels[grep("DOR_", x$order.lab)] = "green2"
labels[grep("G_", x$order.lab)] = "coral1"
labels[grep("R_", x$order.lab)] = "blue3"
labels[grep("DA_", x$order.lab)] = "darkred"
labels[grep("DU_", x$order.lab)] = "darkgoldenrod1"
labels[grep("N_", x$order.lab)] = "darkblue"
labels[grep("V_", x$order.lab)] = "darkgrey"
# Get cluster purity with reference to alledged authors
CP = simpleClusterPurity(x, k = k)
xlab = paste(xlab, "|| Agglomerative coeff. = ", round(x$ac, digits = 2),
"|| CP = ",
round(CP, digits = 2)
)
factoextra::fviz_dend(x, k = k,
k_colors = rep("black", k),
color_labels_by_k = FALSE,
rect = TRUE,
labels_track_height = lth,
label_cols = labels,
cex = cex,
lower_rect = lrect,
main = main, xlab = xlab, ylab = ylab) + theme(plot.margin = margin(5,15,5,5))
}
#
cahPlotCol(myCAH, k = 12)
cutree(CAHLemma, k = 12)
CAHLemma$order.lab
colnames(CAHLemma$data)
rownames(CAHLemma$data)
cutree(CAHLemma, k = 12)
rownames(CAHLemma$data)
?cutree
dendextend::cutree(CAHLemma, k = 12, order_clusters_as_data=FALSE)
dendextend::cutree(as.hclust(CAHLemma), k = 12, order_clusters_as_data=FALSE)
